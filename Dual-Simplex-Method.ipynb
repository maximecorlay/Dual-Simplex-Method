{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEusrVtcunL7956x4DrHgG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Algorithme dual du simplexe: explications et exemple simple\n","\n","### Prérequis: algorithme du simplexe (voir Simplex-Algorithm-Linear-Programming) et méthode branch-and-bound (voir Branch-and-Bound-Diving-Contest)\n","\n","L'algorithme dual du simplexe consiste à partir d'une base telle que les coûts réduits sont négatifs (en maximisation) ou positifs (en minimisation), mais qui n'est pas réalisable (c'est-à-dire que toutes les contraintes ne sont pas vérifiées).\n","\n","Par exemple, considérons le problème suivant:\n","\n","$$\n","\\text{Maximize } -x - y\n","$$\n","$$\n","u = 3 - x - y\n","$$\n","$$\n","v = -2 + x - y\n","$$\n","$$\n","x, y, u, v \\geq 0\n","$$\n","\n","Pour ce problème, $(u,v)$ est clairement une base et elle est telle que les variables hors base ($x$ et $y$) ont un coût réduit négatif. On dit que la base $(u,v)$ est **dual réalisable**.\n","\n","Mais $(u,v)$ n'est pas primal réalisable car  $v=-2$ d'après la 2e contrainte (alors que toutes les variables d'écart doivent être $\\geq 0$ d'après la 3e contrainte).\n","\n","L'algorithme dual du simplexe permet de partir de ce genre de situation et d'atteindre une base primal réalisable optimale.\n","\n","**Mais dans quel genre de situation cela est-il utile ? Ne vaut-il pas mieux appliquer directement l'algorithme du simplexe ?**\n","\n","* Cela est utile quand **on a atteint l'optimum mais qu'on veut rajouter une contrainte**. Dans l'exemple ci-dessus, s'il n'y avait pas la 2e contrainte, nous aurions atteint l'optimum en la base (composée d'un seul élément) $(u)=(3)$, car tous les coûts réduits sont négatifs. Mais l'ajout de la contrainte $v = -2 + x - y$ rend cette base non primal réalisable.\n","* Quand on a atteint l'optimum et qu'on veut rajouter une contrainte, il faut normalement tout recommencer : rajouter une variable d'écart, agrandir les matrices, tout réinverser et recommencer les calculs de l'algo du simplexe. Au lieu de faire tout cela, l'algo dual du simplexe va permettre de **partir de la base optimale précédente** et de l'**ajuster** par très peu de calculs pour satisfaire aux nouvelles contraintes.\n","\n","**Quel est l'intérêt de regarder des problèmes où l'optimum était atteint mais où on ajoute une contrainte après coup ?**\n","\n","C'est typiquement ce dont on a besoin en Programmation Linéaire en Nombres Entiers (PLNE) ! Dans l'algorithme branch-and-bound, on ramifie le problème en sous-problèmes en ajoutant de plus en plus de contraintes. Sans l'algorithme dual du simplexe, il faudrait recommencer les calculs dans chaque branche. Ce serait très long et peu efficace !\n","\n","**Alors, comment se résout le problème ci-dessus ?**\n","\n","* On part de la base $(u,v)$ qui est dual-réalisable mais pas primal réalisable. Pour rappel, elle est duale réalisable car les variables hors base correspondantes ($x$ et $y$) ont un coût réduit négatif (alors qu'on est en maximisation).\n","* On liste les variables de base empêchant la primal-réalisabilité : bien sûr, cela concerne $v$. C'est donc la variable qu'on va faire sortir de la base. On regarde la contrainte correspondante: $v = -2 + x - y$. Ensuite, calculer le minimum des ratios des coûts réduits par l'opposé des coefficients des variables hors base **en ne considérant QUE les variables de coefficient $>0$ (ce qui ne concerne que $x$ ici)**: $min(\\frac{-1}{-1})=1$ donc $x$ entre en base.\n","* Pivoter l'équation $v = -2 + x - y$, qui devient $x=2+y+v$, puis injecter dans tout le problème (contraintes + objectif), ce qui donne:\n","$$\n","\\text{Maximize } -2-2y-v\n","$$\n","$$\n","u = 1 - 2y -v\n","$$\n","$$\n","x=2+y+v\n","$$\n","$$\n","x, y, u, v \\geq 0\n","$$\n","* On constate que la nouvelle base $(u,x)$ est primal-réalisable (et tous les coûts réduits sont négatifs, donc la dual-réalisabilité est vérifiée). L'optimum est donc atteint, et beaucoup plus rapidement que si nous avions fait tous les calculs matriciels de la méthode du simplexe.\n","* Si ce n'était pas le cas, il suffirait de continuer en regardant les contraintes empêchant la réalisabilité (pour les sortir de la base), on calculerait les ratios et ainsi de suite.\n","\n","## Bilan\n","\n","* Malgré son nom, pas besoin de savoir écrire le \"dual\" du problème d'optimisation pour appliquer l'algorithme dual du simplexe: cet algorithme s'applique directement au problème primal !\n","* Cet algo n'est pas très utile si on part de zéro. Par contre, au milieu d'une méthode branch-and-bound de PLNE, il est intéressant d'utiliser le simplexe dual comme ci-dessus quand on ajoute une contrainte (typiquement \"$x \\leq1$\" ou \"$x \\geq 2$\") à un problème dont on connaissait déjà l'optimum car cela évite de réappliquer le simplexe dans chaque noeud et donc de tout recalculer.\n","* Dans l'algo du simplexe, on fait d'abord entrer une variable grâce aux coûts réduits (en prenant celle de coût réduit le plus élevé en maximisation), puis on fait sortir une variable en regardant les contraintes. Dans l'algo du simplexe dual, c'est l'inverse: on fait d'abord sortir une variable en regardant les contraintes, et ensuite on fait entrer une variable en regardant les ratios avec les coûts réduits."],"metadata":{"id":"1pvh_f7N2Bbo"}}]}